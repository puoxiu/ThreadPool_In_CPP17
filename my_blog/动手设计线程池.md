# 使用c++17实现一个线程池

## 相关背景

语法：

* c++11多线程编程：thread、mutex、atomic、condition_variable、unique_lock
* c++11面向对象思想：组合和继承、继承多态、STL容器、bind、function、可变参数模板
* 加深了解c++17和c++20标准中的any类型、semaphore信号量

操作系统：

​	池化技术、内存模型、线程安全、CAS



## 前置知识学习

### 并发与并行

并发与并行的主要区别在于事件的发生时间和执行方式。

并发关注的是在同一时间间隔内处理多个任务，并不是真正的同时运行，而并行则强调在同一时刻多个任务的同时运行。

### IO密集和CPU密集型程序

多线程设计一定更快吗？

不一定。要考虑程序设计是否使用多线程技术，要看程序是IO密集型还是CPU密集型。因为多线程设计上下文切换也是耗费资源的。

**CPU密集：**特点是要进行大量的计算，消耗CPU资源，比如计算圆周率、对视频进行高清解码等等，全靠CPU的运算能力。这种计算密集型任务虽然也可以用多任务完成，但是任务越多，花在任务切换的时间就越多，CPU执行任务的效率就越低，所以，要最高效地利用CPU，计算密集型任务同时进行的数量应当等于CPU的核心数。

**IO密集型**，涉及到网络、磁盘IO的任务都是IO密集型任务，这类任务的特点是CPU消耗很少，任务的大部分时间都在等待IO操作完成（因为IO的速度远远低于CPU和内存的速度），对应的任务（或者线程会阻塞等待）。对于IO密集型任务，线程越多，CPU效率越高，但也有一个限度。常见的大部分任务都是IO密集型任务，比如Web应用。所以**更适合**设计成多线程程序。

### 深入mutex互斥锁和原子类型atomic

c++11提供四种互斥锁：

* std::mutex：独占的互斥锁，不能递归使用
* std::timed_mutex：带超时的独占互斥锁，不能递归使用
* std::recursive_mutex：递归互斥锁，不带超时功能----允许同一线程多次获得互斥锁
* std::recursive_timed_mutex：带超时的递归互斥锁----允许同一线程多次获得互斥锁

通过介绍以上三个函数，使用互斥锁进行线程同步的大致思路主要分为以下几步：

1. 找到多个线程操作的共享资源（全局变量、堆内存、类成员变量等），也可以称之为临界资源
2. 找到和共享资源有关的上下文代码，也就是临界区（下图中的黄色代码部分）
3. 在临界区的上边调用互斥锁类的lock()方法
4. 在临界区的下边调用互斥锁的unlock()方法

其中3 4步可以换成std::lock_guard替代，本质是利用了RAII技术，防止忘记unlock

**atomic**

C++11提供了一个原子类型std::atomic<T>，通过这个原子类型管理的内部变量就可以称之为原子变量，我们可以给原子类型指定bool、char、int、long、指针等类型作为模板参数（不支持浮点类型和复合类型）。

原子指的是一系列不可被CPU上下文交换的机器指令，这些指令组合在一起就形成了原子操作。在多核CPU下，当某个CPU核心开始运行原子操作时，会先暂停其它CPU内核对内存的操作，以保证原子操作不会被其它CPU内核所干扰。

由于原子操作是通过指令提供的支持，因此它的性能相比锁和消息传递会好很多。相比较于锁而言，原子类型不需要开发者处理加锁和释放锁的问题，同时支持修改，读取等操作，还具备较高的并发性能，几乎所有的语言都支持原子类型。

可以看出原子类型是无锁类型，但是无锁不代表无需等待，因为原子类型内部使用了CAS循环，当大量的冲突发生时，该等待还是得等待！但是总归比锁要好。

所以，atomic则是在CPU**指令集**级别对相关指令的lock操作，依赖于硬件直接提供的原子操作的支持，如CAS。CAS 指令尝试比较内存位置的值与给定的期望值，如果相等，则将该内存位置的值设置为新值。这个操作是原子的，即它不会被其他线程打断。

另外，在C++20版本中添加了新的功能函数，可以通过原子类型来阻塞线程，和条件变量中的等待/通知函数是一样的。留给以后深入探讨。

### 条件变量的用法

condition_variable：需要配合std::unique_lock< std::mutex >进行wait操作，也就是阻塞线程的操作。

condition_variable_any可以和任意带有lock()、unlock()语义的mutex搭配使用

> 条件变量通常用于生产者和消费者模型，大致使用过程如下：
>
> 1. 拥有条件变量的线程获取互斥量
> 2. 循环检查某个条件，如果条件不满足阻塞当前线程，否则线程继续向下执行
>    * 产品的数量达到上限，生产者阻塞，否则生产者一直生产。。。
>    * 产品的数量为零，消费者阻塞，否则消费者一直消费。。。
>
> 3. 条件满足之后，可以调用notify_one()或者notify_all()唤醒一个或者所有被阻塞的线程
>    * 由消费者唤醒被阻塞的生产者，生产者解除阻塞继续生产。。。
>    * 由生产者唤醒被阻塞的消费者，消费者解除阻塞继续消费。。。
>
>
> 链接: https://subingwen.cn/cpp/condition/

```c++
/*使用互斥锁和条件变量实现的生产者消费者模型*/
class SyncQueue
{
public:
    SyncQueue(int maxSize) : m_maxSize(maxSize) {}
    // 生产
    void put(const int& x)
    {
        unique_lock<mutex> locker(m_mutex);
        // 判断任务队列是不是已经满了
        while (m_queue.size() == m_maxSize)
        {
            cout << "任务队列已满, 请耐心等待..." << endl;
            // 阻塞线程
            m_notFull.wait(locker);
        }
        // 将任务放入到任务队列中
        m_queue.push_back(x);
        cout << x << " 被生产" << endl; 
        // 通知消费者去消费
        m_notEmpty.notify_one();
    }
	// 消费
    int take()
    {
        unique_lock<mutex> locker(m_mutex);
        while (m_queue.empty())
        {
            cout << "任务队列已空，请耐心等待。。。" << endl;
            m_notEmpty.wait(locker);
        }
        // 从任务队列中取出任务(消费)
        int x = m_queue.front();
        m_queue.pop_front();
        // 通知生产者去生产
        m_notFull.notify_one();
        cout << x << " 被消费" << endl;
        return x;
    }

    bool empty()
    {
        lock_guard<mutex> locker(m_mutex);
        return m_queue.empty();
    }

    bool full()
    {
        lock_guard<mutex> locker(m_mutex);
        return m_queue.size() == m_maxSize;
    }

    int size()
    {
        lock_guard<mutex> locker(m_mutex);
        return m_queue.size();
    }

private:
    list<int> m_queue;     // 存储队列数据
    mutex m_mutex;         // 互斥锁
    condition_variable m_notEmpty;   // 不为空的条件变量
    condition_variable m_notFull;    // 没有满的条件变量
    int m_maxSize;         // 任务队列的最大任务个数
};
```

条件变量condition_variable类的wait()还有一个重载的方法，可以使得程序变得更加精简，而且执行效率更高

```c++
void put(const int& x)
{
    unique_lock<mutex> locker(m_mutex);
    // 根据条件阻塞线程
    m_notFull.wait(locker, [this]() {
        return m_queue.size() != m_maxSize;
    });
    // 将任务放入到任务队列中
    m_queue.push_back(x);
    cout << x << " 被生产" << endl;
    // 通知消费者去消费
    m_notEmpty.notify_one();
}
int take()
{
    unique_lock<mutex> locker(m_mutex);
    m_notEmpty.wait(locker, [this]() {
        return !m_queue.empty();
    });
    // 从任务队列中取出任务(消费)
    int x = m_queue.front();
    m_queue.pop_front();
    // 通知生产者去生产
    m_notFull.notify_one();
    cout << x << " 被消费" << endl;
    return x;
}
```



### 信号量（C++20）

资源计数--PV操作

c++20提供了信号量库

这里基于mutex和condition_variable简单实现：

```c++
class Semaphore {
public:
    Semaphore(int p = 0): p_(p) {};
    ~Semaphore() = default;

    // p
    void wait() {
        std::unique_lock<std::mutex> locker(mtx_);
        conv_.wait(locker, [&](){
            return p_ > 0;
        });
        p_--;
    }
    // v
    void post() {
        std::unique_lock<std::mutex> loacker(mtx_);
        p_++;
        conv_.notify_all();
    }
private:
    int p_;

    std::mutex mtx_;
    std::condition_variable conv_;
};
```



### Any（c++17）

先简单应用，后面深入学习

使用场景：不同任务的返回值可能不同，因此需要一个可以指定任意类型的返回值



## 整体架构设计

线程池类：

```c++
// 线程工作模式
enum class PoolMode {
    MODE_FIXED,
    MODE_CACHE,
};

class ThreadPool {
public:
    ThreadPool();
    ~ThreadPool();

    void start(size_t initThraedSize = std::thread::hardware_concurrency());    // 开始运行-创建并初始化所有线程
    void setMode(PoolMode mode);        // 设置工作模式
    void setTaskQueueThreshHold(size_t threshhold);
    void setThreadSizeThreshHold(size_t threshhold);

    size_t getThreadSize() const;

    Result submitTask(std::shared_ptr<Task> task);        // 提交任务给任务队列

    ThreadPool(const ThreadPool&) = delete;             // 禁止拷贝构造和赋值构造
    ThreadPool& operator= (const ThreadPool&) = delete;

private:
    void threadFunc(size_t threadID);	// 线程函数
    bool checkRunningStatus() const;

private:
    // std::vector<std::unique_ptr<Thread>> threads_;
    std::unordered_map<size_t, std::unique_ptr<Thread>> threads_;       // 所有线程

    size_t initThreadSize_;                 // 初始化线程数量
    size_t threadSizeMAXThreshHold_;        // 最大线程数量
    std::atomic_size_t idleThreadSize_;        // 空闲线程数量
    std::atomic_size_t curThreadSize_;         // 当前线程总数量
    
    // std::queue<Task*> tasks;
    std::queue<std::shared_ptr<Task>> taskQueue_;   // 任务队列
    std::atomic_uint taskSize_;
    size_t taskSizeMAXThreshHold_;       // 任务队列数量最大阈值

    // 线程安全
    std::mutex taskQueueMtx_;
    std::condition_variable notFull_;
    std::condition_variable notEmpty_;
    std::condition_variable exitCond_;
    
    PoolMode mode_;
    std::atomic_bool isPoolRunning_;
};
```

线程类：

```c++
// 线程类--构造函数传入函数绑定器，运行线程池传入的函数
class Thread {
public:
    using ThreadFunc = std::function<void(size_t)>;

    Thread(ThreadFunc func);
    ~Thread();

    void start();
    size_t getThreadID() const;

private:
    ThreadFunc func_;
    size_t threadID_;
    static size_t generatID;
};
```

任务基类

```c++
// 任务基类
class Task {
public:
    Task() ;
    ~Task() =default;
    void exec();
    void setResult(Result *res);
    virtual any run() = 0;
private:
    Result *result_;
};
```

返回结果类

```c++
// 提交到线程池的执行返回结果类
class Result {
public:
    Result(std::shared_ptr<Task> task, bool isValid = true) ;
    ~Result() = default;

    void setVal(any any);

    any get();
private:
    any any_;
    Semaphore sem_;
    std::shared_ptr<Task> task_;  // 指向对应任务对象
    std::atomic_bool isValid_;  
};
```



### 线程池线程数量怎么设定？

数量肯定不是越多越好，应怎么设定线程数量参数？

* 线程的创建和销毁都是消耗资源的，
* 线程栈本身占用大量内存（pthread结构体）
* 上下文切换过于频繁占用时间
* 大量线程同时唤醒会使系统经常出现瞬间负载很大，CPU占用激增，从而可能导致宕机

另外，线程没有自己独立的地址空间，所有同进程的线程是共享地址空间的。

使用ulimit命令查看线程栈大小：

```shell
ulimit -a
# 输出
stack size                  (kbytes, -s) 8192	#即每个栈空间大小8M
x user processes                  (-u) 30941
```

读c++开源库如muduo、libevent发现，其多线程设计一般按照系统CPU核心数量设计。可以设计为：

* CPU密集型：线程数 = 核心数 + 1
* IO密集型：设计为2倍核心数或者根据io比例调整

此项目默认设计初始化为核心数目 通过：

```c++
 size_t initThraedSize = std::thread::hardware_concurrency()
```



### 线程池的fixed模式和cached模式

fixed模式：线程数量固定

cached模式：线程数量可变

​	IO高峰期需要更多线程，可动态增长，	设计超时时间：超时没有任务的线程进行销毁

### ThreadPool类与参数设计

### Any上帝类

**问题：**设计任务类时，Task作为基类留下接口：virtual void run() = 0; 但是有时候用户需要接受任务的执行结果，也就是需要有返回值，同时其类型不确定。
解决1：类模板

解决2：Any

c++17已经实现，

参考之前自己实现的一个Any万能类型，这里正好派上用场：

```c++
class Any {
public:
    Any() = default;
    ~Any() = default;
    Any(const Any&) = delete;
    Any& operator=(const Any&) = delete;
    Any(Any&&) = default;
    Any& operator=(Any&&) = default;

    template<typename T>
    Any(T data) : base_(std::make_unique<Derive<T>>(data)) {}

    template<typename T>
    T cast_() {
        Derive<T>* pd = dynamic_cast<Derive<T>>(this->base_.get());
        if(pd == nullptr) {
            throw "type is unmatch.";
        }
        return pd;
    }

private:
    class Base {
        public:
            virtual ~Base() = default;
    };
    // 
    template<typename T>
    class Derive : public Base {
        public:
            Derive(T data) : data_(data) {}

            T data_;        // 保存的数据
    };
    std::unique_ptr<Base> base_;
};
```



## 开发中遇到的问题：

### 1、unique_ptr智能指针

资源转移后继续使用导致段错误。这种错误编译器没有提示，在实际使用中要注意！

```c++
// 错误代码
auto ptr = std::make_unique<Thread>(std::bind(&ThreadPool::threadFunc, this, std::placeholders::_1));
threads_[ptr->getThreadID()] = std::move(ptr);	// 资源已转移
threads_[ptr->getThreadID()]->start();

// 修改
auto ptr = std::make_unique<Thread>(std::bind(&ThreadPool::threadFunc, this, std::placeholders::_1));
auto id = ptr->getThreadID();
threads_[id] = std::move(ptr);
threads_[id]->start();
```

### 2、线程死锁问题

实现线程池的析构函数：

```c++
ThreadPool::~ThreadPool() {
    isPoolRunning_ = false;

    std::unique_lock<std::mutex> locker(taskQueueMtx_);
    notEmpty_.notify_all();
    // std::unique_lock<std::mutex> locker(taskQueueMtx_);
    exitCond_.wait(locker, [&](){
        return threads_.size() == 0;
    });
}
```



死锁1

注意析构函数获取锁和notify的位置

死锁2

在fixed模式下，当任务队列为空时线程阻塞，这时没有任务需要执行且用户调用了析构函数来销毁线程池，如果是下面代码则会死锁

```c++
notEmpty_.wait(locker, [&](){
	return !taskQueue_.empty();
});
```

是由于线程虽然被析构函数notify,但由于任务队列为空任然会处于wait状态，修改：

```c++
notEmpty_.wait(locker);
```

> 在C++中，如果一个线程获取了一个互斥锁（通常通过`std::mutex`类实现），然后调用了某个条件变量（`std::condition_variable`）的`wait`函数，那么这个线程会释放它所持有的互斥锁。这是条件变量和互斥锁协同工作的标准行为，目的是允许其他等待该互斥锁的线程有机会执行。
>
> 当条件满足时，其他线程可以通过条件变量的`notify_one`或`notify_all`函数唤醒一个或所有等待的线程。被唤醒的线程随后会尝试重新获取互斥锁（这是在`wait`函数内部自动进行的），一旦成功获取到锁，它们将继续执行。

即在新的代码中虽然所有处于wait状态的线程都会被notify, 但由于仍然要获取互斥锁，所以不会造成临界区访问问题。



### 线程池的回收

唤醒所有阻塞线程，并设置线程池运行状态为false











